{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "924aa10d-1ff6-4f7b-ada3-6f591667f785",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import gym\n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 16\n",
    "PERCENTILE = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3cca1a35-84e7-41f0-ba1b-76131e9d26ef",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                   Version\n",
      "------------------------- --------------\n",
      "absl-py                   2.1.0\n",
      "ale-py                    0.10.1\n",
      "anyio                     4.5.0\n",
      "argon2-cffi               23.1.0\n",
      "argon2-cffi-bindings      21.2.0\n",
      "arrow                     1.3.0\n",
      "asttokens                 2.4.1\n",
      "async-lru                 2.0.4\n",
      "attrs                     24.2.0\n",
      "babel                     2.16.0\n",
      "backcall                  0.2.0\n",
      "beautifulsoup4            4.12.3\n",
      "bleach                    6.1.0\n",
      "Brotli                    1.0.9\n",
      "cached-property           1.5.2\n",
      "cachetools                5.5.0\n",
      "certifi                   2024.8.30\n",
      "cffi                      1.17.0\n",
      "charset-normalizer        3.4.0\n",
      "cloudpickle               3.1.0\n",
      "comm                      0.2.2\n",
      "debugpy                   1.6.7\n",
      "decorator                 4.4.2\n",
      "defusedxml                0.7.1\n",
      "EasyProcess               1.1\n",
      "entrypoints               0.4\n",
      "exceptiongroup            1.2.2\n",
      "executing                 2.1.0\n",
      "Farama-Notifications      0.0.4\n",
      "fastjsonschema            2.20.0\n",
      "filelock                  3.16.1\n",
      "fqdn                      1.5.1\n",
      "fsspec                    2024.10.0\n",
      "google-auth               2.36.0\n",
      "google-auth-oauthlib      1.0.0\n",
      "grpcio                    1.68.1\n",
      "gym                       0.26.2\n",
      "gym-notices               0.0.8\n",
      "gymnasium                 1.0.0\n",
      "h11                       0.14.0\n",
      "h2                        4.1.0\n",
      "hpack                     4.0.0\n",
      "httpcore                  1.0.7\n",
      "httpx                     0.27.2\n",
      "hyperframe                6.0.1\n",
      "idna                      3.10\n",
      "imageio                   2.35.1\n",
      "imageio-ffmpeg            0.5.1\n",
      "importlib_metadata        8.5.0\n",
      "importlib_resources       6.4.5\n",
      "ipykernel                 6.29.5\n",
      "ipython                   8.12.2\n",
      "isoduration               20.11.0\n",
      "jedi                      0.19.1\n",
      "Jinja2                    3.1.4\n",
      "json5                     0.9.25\n",
      "jsonpointer               3.0.0\n",
      "jsonschema                4.23.0\n",
      "jsonschema-specifications 2024.10.1\n",
      "jupyter_client            8.6.3\n",
      "jupyter_core              5.7.2\n",
      "jupyter-events            0.10.0\n",
      "jupyter-lsp               2.2.5\n",
      "jupyter_server            2.14.2\n",
      "jupyter_server_terminals  0.5.3\n",
      "jupyterlab                4.3.0\n",
      "jupyterlab_pygments       0.3.0\n",
      "jupyterlab_server         2.27.3\n",
      "Markdown                  3.7\n",
      "MarkupSafe                2.1.5\n",
      "matplotlib-inline         0.1.7\n",
      "mistune                   3.0.2\n",
      "moviepy                   1.0.3\n",
      "mpmath                    1.3.0\n",
      "nbclient                  0.10.1\n",
      "nbconvert                 7.16.4\n",
      "nbformat                  5.10.4\n",
      "nest_asyncio              1.6.0\n",
      "networkx                  3.1\n",
      "notebook_shim             0.2.4\n",
      "numpy                     1.24.4\n",
      "nvidia-cublas-cu12        12.1.3.1\n",
      "nvidia-cuda-cupti-cu12    12.1.105\n",
      "nvidia-cuda-nvrtc-cu12    12.1.105\n",
      "nvidia-cuda-runtime-cu12  12.1.105\n",
      "nvidia-cudnn-cu12         9.1.0.70\n",
      "nvidia-cufft-cu12         11.0.2.54\n",
      "nvidia-curand-cu12        10.3.2.106\n",
      "nvidia-cusolver-cu12      11.4.5.107\n",
      "nvidia-cusparse-cu12      12.1.0.106\n",
      "nvidia-nccl-cu12          2.20.5\n",
      "nvidia-nvjitlink-cu12     12.6.85\n",
      "nvidia-nvtx-cu12          12.1.105\n",
      "oauthlib                  3.2.2\n",
      "opencv-python             4.10.0.84\n",
      "overrides                 7.7.0\n",
      "packaging                 24.2\n",
      "pandocfilters             1.5.0\n",
      "parso                     0.8.4\n",
      "pexpect                   4.9.0\n",
      "pickleshare               0.7.5\n",
      "pillow                    10.4.0\n",
      "pip                       24.3.1\n",
      "pkgutil_resolve_name      1.3.10\n",
      "platformdirs              4.3.6\n",
      "proglog                   0.1.10\n",
      "prometheus_client         0.21.0\n",
      "prompt_toolkit            3.0.48\n",
      "protobuf                  5.29.1\n",
      "psutil                    6.0.0\n",
      "ptyprocess                0.7.0\n",
      "pure_eval                 0.2.3\n",
      "pyasn1                    0.6.1\n",
      "pyasn1_modules            0.4.1\n",
      "pycparser                 2.22\n",
      "Pygments                  2.18.0\n",
      "PySocks                   1.7.1\n",
      "python-dateutil           2.9.0\n",
      "python-json-logger        2.0.7\n",
      "pytz                      2024.2\n",
      "PyVirtualDisplay          0.2.5\n",
      "PyYAML                    6.0.2\n",
      "pyzmq                     25.1.2\n",
      "referencing               0.35.1\n",
      "requests                  2.32.3\n",
      "requests-oauthlib         2.0.0\n",
      "rfc3339-validator         0.1.4\n",
      "rfc3986-validator         0.1.1\n",
      "rpds-py                   0.20.0\n",
      "rsa                       4.9\n",
      "Send2Trash                1.8.3\n",
      "setuptools                75.1.0\n",
      "six                       1.16.0\n",
      "sniffio                   1.3.1\n",
      "soupsieve                 2.5\n",
      "stack-data                0.6.2\n",
      "sympy                     1.13.3\n",
      "tensorboard               2.14.0\n",
      "tensorboard-data-server   0.7.2\n",
      "tensorboardX              2.6.2.2\n",
      "terminado                 0.18.1\n",
      "tinycss2                  1.4.0\n",
      "tomli                     2.0.2\n",
      "torch                     2.4.1\n",
      "torchvision               0.19.1\n",
      "tornado                   6.4.1\n",
      "tqdm                      4.67.1\n",
      "traitlets                 5.14.3\n",
      "triton                    3.0.0\n",
      "types-python-dateutil     2.9.0.20241003\n",
      "typing_extensions         4.12.2\n",
      "typing-utils              0.1.0\n",
      "uri-template              1.3.0\n",
      "urllib3                   2.2.3\n",
      "wcwidth                   0.2.13\n",
      "webcolors                 24.8.0\n",
      "webencodings              0.5.1\n",
      "websocket-client          1.8.0\n",
      "Werkzeug                  3.0.6\n",
      "wheel                     0.44.0\n",
      "zipp                      3.20.2\n",
      "zstandard                 0.23.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1cfe36d-aa43-4763-b988-828aff8f2e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4192, 0.5213, 0.0595],\n",
      "        [0.6201, 0.1152, 0.2647]])\n",
      "<built-in method size of Tensor object at 0x792944afcf90>\n"
     ]
    }
   ],
   "source": [
    "m = nn.Softmax(dim=1)\n",
    "input = torch.randn(2, 3)\n",
    "output = m(input)\n",
    "print(output)\n",
    "print(output.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68c31401-4e72-49d9-9a81-6633c48f2f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, obs_size, hidden_size, n_actions):\n",
    "        super(Net, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(obs_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, n_actions)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7e80f67-1514-4cf9-837d-af353adee675",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4215724458.py, line 23)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[24], line 23\u001b[0;36m\u001b[0m\n\u001b[0;31m    act_probs_v = sm(net(obs_v_1d))\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Episode = namedtuple('Episode', field_names=['reward', 'steps'])\n",
    "EpisodeStep = namedtuple('EpisodeStep', field_names=['observation', 'action'])\n",
    "\n",
    "\n",
    "def iterate_batches(env, net, batch_size):\n",
    "    batch = []\n",
    "    episode_reward = 0.0\n",
    "    episode_steps = []\n",
    "    obs = env.reset()\n",
    "    sm = nn.Softmax(dim=1)\n",
    "    while True:\n",
    "      print(obs)\n",
    "      print(obs[0].shape)\n",
    "      obs_v = torch.FloatTensor(obs[0])\n",
    "      obs_v_1d = obs_v.unsqueeze(0)\n",
    "      print(obs_v_1d.shape)\n",
    "      print(net(obs_v))\n",
    "      print(type(net(obs_v)))\n",
    "      print(net(obs_v).shape)\n",
    "      print(net(obs_v).size())\n",
    "      #sm(net(obs_v))\n",
    "      print(sm(net(obs_v_1d))\n",
    "      act_probs_v = sm(net(obs_v_1d))\n",
    "      #print(act_probs_v.ndim)\n",
    "      #print(act_probs_v.shape)\n",
    "      act_probs = act_probs_v.data.numpy()[0]\n",
    "      #print(act_probs.ndim)\n",
    "      #print(act_probs.shape)\n",
    "      action = np.random.choice(len(act_probs), p=act_probs)\n",
    "      obs, reward, terminated,truncated, info = env.step(action)\n",
    "      episode_reward += reward\n",
    "      episode_steps.append(EpisodeStep(observation=obs, action=action))\n",
    "        if terminated:\n",
    "            batch.append(Episode(reward=episode_reward, steps=episode_steps))\n",
    "            episode_reward = 0.0\n",
    "            episode_steps = []\n",
    "            next_obs = env.reset()\n",
    "            if len(batch) == batch_size:\n",
    "                yield batch\n",
    "                batch = []\n",
    "        obs = next_obs\n",
    "        #return print(act_probs_v.ndim , act_probs.ndim )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "642e6682-af05-4ac0-80ce-3db17a7d06c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_batch(batch, percentile):\n",
    "    rewards = list(map(lambda s: s.reward, batch))\n",
    "    reward_bound = np.percentile(rewards, percentile)\n",
    "    reward_mean = float(np.mean(rewards))\n",
    "\n",
    "    train_obs = []\n",
    "    train_act = []\n",
    "    for example in batch:\n",
    "        if example.reward < reward_bound:\n",
    "            continue\n",
    "        train_obs.extend(map(lambda step: step.observation, example.steps))\n",
    "        train_act.extend(map(lambda step: step.action, example.steps))\n",
    "\n",
    "    train_obs_v = torch.FloatTensor(train_obs)\n",
    "    train_act_v = torch.LongTensor(train_act)\n",
    "    return train_obs_v, train_act_v, reward_bound, reward_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52c3285d-35f5-46e4-b2c0-41640031501d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'iterate_batches' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(params\u001b[38;5;241m=\u001b[39mnet\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m     10\u001b[0m writer \u001b[38;5;241m=\u001b[39m SummaryWriter(comment\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-cartpole\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m iter_no, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43miterate_batches\u001b[49m(env, net, BATCH_SIZE)):\n\u001b[1;32m     13\u001b[0m     obs_v, acts_v, reward_b, reward_m \u001b[38;5;241m=\u001b[39m filter_batch(batch, PERCENTILE)\n\u001b[1;32m     14\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'iterate_batches' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    env = gym.make(\"CartPole-v1\")\n",
    "    # env = gym.wrappers.Monitor(env, directory=\"mon\", force=True)\n",
    "    obs_size = env.observation_space.shape[0]\n",
    "    n_actions = env.action_space.n\n",
    "\n",
    "    net = Net(obs_size, HIDDEN_SIZE, n_actions)\n",
    "    objective = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(params=net.parameters(), lr=0.01)\n",
    "    writer = SummaryWriter(comment=\"-cartpole\")\n",
    "\n",
    "    for iter_no, batch in enumerate(iterate_batches(env, net, BATCH_SIZE)):\n",
    "        obs_v, acts_v, reward_b, reward_m = filter_batch(batch, PERCENTILE)\n",
    "        optimizer.zero_grad()\n",
    "        action_scores_v = net(obs_v)\n",
    "        loss_v = objective(action_scores_v, acts_v)\n",
    "        loss_v.backward()\n",
    "        optimizer.step()\n",
    "        print(\"%d: loss=%.3f, reward_mean=%.1f, reward_bound=%.1f\" % (\n",
    "            iter_no, loss_v.item(), reward_m, reward_b))\n",
    "        writer.add_scalar(\"loss\", loss_v.item(), iter_no)\n",
    "        writer.add_scalar(\"reward_bound\", reward_b, iter_no)\n",
    "        writer.add_scalar(\"reward_mean\", reward_m, iter_no)\n",
    "        if reward_m > 199:\n",
    "            print(\"Solved!\")\n",
    "            break\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5be1b5a5-dfe5-40ac-ae1b-2bd3e7788b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 128, 128])\n",
      "torch.Size([3, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# Create a sample tensor\n",
    "tensor = torch.randn(3, 224, 224)\n",
    "\n",
    "# Define the resize transform\n",
    "resize = T.Resize((128, 128))\n",
    "\n",
    "# Apply the transform\n",
    "resized_tensor = resize(tensor)\n",
    "\n",
    "print(resized_tensor.shape)\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Create a sample tensor\n",
    "tensor = torch.randn(3, 224, 224)\n",
    "\n",
    "# Resize the tensor\n",
    "resized_tensor = F.interpolate(tensor.unsqueeze(0), size=(128, 128), mode='bilinear', align_corners=False).squeeze(0)\n",
    "\n",
    "print(resized_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9e63cefb-7cbf-4c2d-9841-d6a32ebc6c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5000, 1.5000, 0.1000],\n",
      "        [2.2000, 1.3000, 1.7000]])\n",
      "tensor([1., 2.])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Long but found Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# tensor([1, 2])\u001b[39;00m\n\u001b[1;32m     12\u001b[0m loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m---> 13\u001b[0m cel \u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myhat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(cel)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# tensor(0.8393)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/Rl_train/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Rl_train/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/Rl_train/lib/python3.8/site-packages/torch/nn/modules/loss.py:1188\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1189\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Rl_train/lib/python3.8/site-packages/torch/nn/functional.py:3104\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3103\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Long but found Float"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "yhat = torch.Tensor([[0.5, 1.5, 0.1], [2.2, 1.3, 1.7]])\n",
    "print(yhat)\n",
    "# tensor([[0.5000, 1.5000, 0.1000],\n",
    "#         [2.2000, 1.3000, 1.7000]])\n",
    "\n",
    "y = torch.Tensor([1, 2])\n",
    "print(y)\n",
    "# tensor([1, 2])\n",
    "\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "cel = loss(input=yhat, target=y)\n",
    "print(cel)\n",
    "# tensor(0.8393)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c4c8229b-21b5-4b5f-ad55-6108560a96d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2573623178.py, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[43], line 8\u001b[0;36m\u001b[0m\n\u001b[0;31m    y =  = torch.Tensor([0, 1, 0])\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "yhat = torch.Tensor([0.5, 1.5, 0.1])\n",
    "print(yhat)\n",
    "# tensor([0.5000, 1.5000, 0.1000])\n",
    "\n",
    "#y = torch.Tensor([0, 1, 0]).to(torch.long)\n",
    "y =  = torch.Tensor([0, 1, 0])\n",
    "print(y)\n",
    "# tensor([0, 1, 0])\n",
    "\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "cel = loss(input=yhat, target=y)\n",
    "print(cel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5c879b3a-5e83-4dc1-aa1a-4b18aeb58a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0903, 0.1525]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.linear = nn.Linear(10, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# Creating an instance of the model and performing a forward pass\n",
    "model = SimpleModel()\n",
    "input_data = torch.randn(1, 10)\n",
    "output = model(input_data)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0d185eaf-b147-408c-ab40-da584e4a5f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0903, 0.1525], grad_fn=<SelectBackward0>)\n",
      "tensor(0.1525, grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.0903, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(output[0])\n",
    "print(output[0,-1])\n",
    "output[-1,0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL_train",
   "language": "python",
   "name": "rl_train"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
